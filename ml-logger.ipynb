{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "from numpy import loadtxt\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date, time\n",
    "from xgboost import plot_tree\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import math\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.9 ms\n",
      "Accuracy: 82.50% (10.00%)\n",
      "Accuracy: 77.50% (9.35%)\n",
      "patient XGB: 0.13333333333333333\n",
      "patient LR: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "cname = ['F43','F42','F34','F32','F31','F29','F24','F21','F13','F6']\n",
    "t_final = pd.DataFrame()\n",
    "path2 = 'C:/Users/Husse/Desktop/iGraspProject/Hardware/Patients/Grasp/'\n",
    "\n",
    "for file in os.listdir(path2):\n",
    "    test_df = pd.read_csv(path2+file, header=None, names=cname)\n",
    "    file_split = file.split(sep='-')\n",
    "    file_split2 = file_split[2].split(sep='.')\n",
    "     \n",
    "    t_final.loc[i,'mF6'] = test_df['F6'].mean()\n",
    "    t_final.loc[i,'mF13'] = test_df['F13'].mean()\n",
    "    t_final.loc[i,'mF21'] = test_df['F21'].mean()\n",
    "    t_final.loc[i,'mF24'] = test_df['F24'].mean()\n",
    "    t_final.loc[i,'mF29'] = test_df['F29'].mean()\n",
    "    t_final.loc[i,'mF31'] = test_df['F31'].mean()\n",
    "#     t_final.loc[i,'mF32'] = test_df['F32'].mean()\n",
    "    t_final.loc[i,'mF34'] = test_df['F34'].mean()\n",
    "    t_final.loc[i,'mF42'] = test_df['F42'].mean()\n",
    "    t_final.loc[i,'mF43'] = test_df['F43'].mean()\n",
    "\n",
    "#     t_final.loc[i,'miF6'] = test_df['F6'].min()\n",
    "#     t_final.loc[i,'miF13'] = test_df['F13'].min()\n",
    "#     t_final.loc[i,'miF21'] = test_df['F21'].min()\n",
    "#     t_final.loc[i,'miF24'] = test_df['F24'].min()\n",
    "#     t_final.loc[i,'miF29'] = test_df['F29'].min()\n",
    "#     t_final.loc[i,'miF31'] = test_df['F31'].min()\n",
    "#     t_final.loc[i,'miF32'] = test_df['F32'].min()\n",
    "#     t_final.loc[i,'miF34'] = test_df['F34'].min()\n",
    "#     t_final.loc[i,'miF42'] = test_df['F42'].min()\n",
    "#     t_final.loc[i,'miF43'] = test_df ['F43'].min()\n",
    "    \n",
    "#     t_final.loc[i,'sF6'] = test_df['F6'].std()\n",
    "#     t_final.loc[i,'sF13'] = test_df['F13'].std()\n",
    "#     t_final.loc[i,'sF21'] = test_df['F21'].std()\n",
    "#     t_final.loc[i,'sF24'] = test_df['F24'].std()\n",
    "#     t_final.loc[i,'sF29'] = test_df['F29'].std()\n",
    "#     t_final.loc[i,'sF31'] = test_df['F31'].std()\n",
    "# #     t_final.loc[i,'sF32'] = test_df['F32'].std()\n",
    "#     t_final.loc[i,'sF34'] = test_df['F34'].std()\n",
    "#     t_final.loc[i,'sF42'] = test_df['F42'].std()\n",
    "#     t_final.loc[i,'sF43'] = test_df['F43'].std()\n",
    "    \n",
    "    t_final.loc[i,'rF6'] = np.sqrt(sum(test_df['F6']**2)/len(test_df))\n",
    "    t_final.loc[i,'rF13'] = np.sqrt(sum(test_df['F13']**2)/len(test_df))\n",
    "    t_final.loc[i,'rF21'] = np.sqrt(sum(test_df['F21']**2)/len(test_df))\n",
    "    t_final.loc[i,'rF24'] = np.sqrt(sum(test_df['F24']**2)/len(test_df))\n",
    "    t_final.loc[i,'rF29'] = np.sqrt(sum(test_df['F29']**2)/len(test_df))\n",
    "    t_final.loc[i,'rF31'] = np.sqrt(sum(test_df['F31']**2)/len(test_df))\n",
    "#     t_final.loc[i,'rF32'] = np.sqrt(sum(test_df['F32']**2)/len(test_df))\n",
    "    t_final.loc[i,'rF34'] = np.sqrt(sum(test_df['F34']**2)/len(test_df))\n",
    "    t_final.loc[i,'rF42'] = np.sqrt(sum(test_df['F42']**2)/len(test_df))\n",
    "    t_final.loc[i,'rF43'] = np.sqrt(sum(test_df['F43']**2)/len(test_df))\n",
    "    \n",
    "    t_final.loc[i,'Label'] = math.floor(int(file_split2[0])/10)\n",
    "    i+=1\n",
    "    \n",
    "i = 0\n",
    "final = pd.DataFrame()\n",
    "path = 'C:/Users/Husse/Desktop/iGraspProject/Hardware/Samples/Grasp/'\n",
    "\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    df = pd.read_csv(path+file, header=None, names=cname)\n",
    "    file_split = file.split(sep='-')\n",
    "    file_split2 = file_split[2].split(sep='.')\n",
    "     \n",
    "    final.loc[i,'mF6'] = df['F6'].mean()\n",
    "    final.loc[i,'mF13'] = df['F13'].mean()\n",
    "    final.loc[i,'mF21'] = df['F21'].mean()\n",
    "    final.loc[i,'mF24'] = df['F24'].mean()\n",
    "    final.loc[i,'mF29'] = df['F29'].mean()\n",
    "    final.loc[i,'mF31'] = df['F31'].mean()\n",
    "#     final.loc[i,'mF32'] = df['F32'].mean()\n",
    "    final.loc[i,'mF34'] = df['F34'].mean()\n",
    "    final.loc[i,'mF42'] = df['F42'].mean()\n",
    "    final.loc[i,'mF43'] = df['F43'].mean()\n",
    "\n",
    "#     final.loc[i,'miF6'] = df['F6'].min()\n",
    "#     final.loc[i,'miF13'] = df['F13'].min()\n",
    "#     final.loc[i,'miF21'] = df['F21'].min()\n",
    "#     final.loc[i,'miF24'] = df['F24'].min()\n",
    "#     final.loc[i,'miF29'] = df['F29'].min()\n",
    "#     final.loc[i,'miF31'] = df['F31'].min()\n",
    "#     final.loc[i,'miF32'] = df['F32'].min()\n",
    "#     final.loc[i,'miF34'] = df['F34'].min()\n",
    "#     final.loc[i,'miF42'] = df['F42'].min()\n",
    "#     final.loc[i,'miF43'] = df ['F43'].min()\n",
    "    \n",
    "#     final.loc[i,'sF6'] = df['F6'].std()\n",
    "#     final.loc[i,'sF13'] = df['F13'].std()\n",
    "#     final.loc[i,'sF21'] = df['F21'].std()\n",
    "#     final.loc[i,'sF24'] = df['F24'].std()\n",
    "#     final.loc[i,'sF29'] = df['F29'].std()\n",
    "#     final.loc[i,'sF31'] = df['F31'].std()\n",
    "# #     final.loc[i,'sF32'] = df['F32'].std()\n",
    "#     final.loc[i,'sF34'] = df['F34'].std()\n",
    "#     final.loc[i,'sF42'] = df['F42'].std()\n",
    "#     final.loc[i,'sF43'] = df['F43'].std()\n",
    "    \n",
    "    final.loc[i,'rF6'] = np.sqrt(sum(df['F6']**2)/len(df))\n",
    "    final.loc[i,'rF13'] = np.sqrt(sum(df['F13']**2)/len(df))\n",
    "    final.loc[i,'rF21'] = np.sqrt(sum(df['F21']**2)/len(df))\n",
    "    final.loc[i,'rF24'] = np.sqrt(sum(df['F24']**2)/len(df))\n",
    "    final.loc[i,'rF29'] = np.sqrt(sum(df['F29']**2)/len(df))\n",
    "    final.loc[i,'rF31'] = np.sqrt(sum(df['F31']**2)/len(df))\n",
    "#     final.loc[i,'rF32'] = np.sqrt(sum(df['F32']**2)/len(df))\n",
    "    final.loc[i,'rF34'] = np.sqrt(sum(df['F34']**2)/len(df))\n",
    "    final.loc[i,'rF42'] = np.sqrt(sum(df['F42']**2)/len(df))\n",
    "    final.loc[i,'rF43'] = np.sqrt(sum(df['F43']**2)/len(df))\n",
    "    \n",
    "    final.loc[i,'Label'] = math.floor(int(file_split2[0])/10)\n",
    "    i+=1\n",
    "    \n",
    "    \n",
    "X = final.copy()\n",
    "del X['Label']\n",
    "\n",
    "y = final['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(max_depth=3,learning_rate=0.7)\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "eval_metric = [\"merror\"]\n",
    "\n",
    "%time xgb_model.fit(X_train, y_train, eval_metric=eval_metric, eval_set=eval_set, verbose=False, early_stopping_rounds=10)\n",
    "# print('Accuracy of XGB classifier on training set: {:.2f}'\n",
    "#        .format(xgb_model.score(X_train, y_train)))\n",
    "# print('Accuracy of XGB classifier on test set: {:.2f}'\n",
    "#        .format(xgb_model.score(X_test[X_train.columns], y_test)))\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "final['p'] = xgb_model.predict(X)\n",
    "# plot_importance(xgb_model)\n",
    "# pyplot.show()\n",
    "# print(classification_report(y_test, y_pred))\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=None)\n",
    "results = cross_val_score(xgb_model, X, y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "X = final.copy()\n",
    "X = X.drop(columns=['Label','p'])\n",
    "\n",
    "y = final['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "logmodel = LogisticRegression(max_iter = 200, multi_class='multinomial')\n",
    "logmodel.fit(X_train,y_train)\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# print('Accuracy of LR training set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "# print('Accuracy of LR test set: {:.2f}'.format(clf.score(X_test[X_train.columns], y_test)))\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "# print(clf.score(X_test,y_test))\n",
    "# print()\n",
    "# print(classification_report(y_test, y_pred))\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=None)\n",
    "results = cross_val_score(logmodel, X, y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "x_pat = t_final.drop(columns=['Label'])\n",
    "t_final['lr_pred'] = clf.predict(x_pat)\n",
    "t_final['xgb_pred'] = xgb_model.predict(x_pat)\n",
    "print('patient XGB:',len(t_final[t_final['Label']==t_final['xgb_pred']])/len(t_final))\n",
    "print('patient LR:',len(t_final[t_final['Label']==t_final['lr_pred']])/len(t_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "cname = ['F43','F42','F34','F32','FSR4','FSR5']\n",
    "t_final = pd.DataFrame()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.84 ms\n",
      "Accuracy: 75.00% (0.00%)\n",
      "Accuracy: 70.00% (12.75%)\n",
      "patient XGB: 0.8\n",
      "patient LR: 0.6\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "cname = ['F43','F42','F34','F32','FSR4','FSR5']\n",
    "final = pd.DataFrame()\n",
    "t_final = pd.DataFrame()\n",
    "path = 'C:/Users/Husse/Desktop/iGraspProject/Hardware/Samples/Pinch/'\n",
    "path2 = 'C:/Users/Husse/Desktop/iGraspProject/Hardware/Patients/Pinch/'\n",
    "\n",
    "for file in os.listdir(path2):\n",
    "    try:\n",
    "        test_df = pd.DataFrame()\n",
    "        test_df = pd.read_csv(path2+file, header=None, names=cname)\n",
    "        file_split = file.split(sep='-')\n",
    "        file_split2 = file_split[2].split(sep='.')\n",
    "\n",
    "\n",
    "        t_final.loc[i,'mFSR5'] = test_df['FSR5'].mean()\n",
    "        t_final.loc[i,'mFSR4'] = test_df['FSR4'].mean()\n",
    "        t_final.loc[i,'mF32'] = test_df['F32'].mean()\n",
    "        t_final.loc[i,'mF34'] = test_df['F34'].mean()\n",
    "        t_final.loc[i,'mF42'] = test_df['F42'].mean()\n",
    "        t_final.loc[i,'mF43'] = test_df['F43'].mean()\n",
    "\n",
    "#         t_final.loc[i,'miFSR5'] = test_df['FSR5'].max()\n",
    "#         t_final.loc[i,'miFSR4'] = test_df['FSR4'].max()\n",
    "\n",
    "\n",
    "        t_final.loc[i,'miF32'] = test_df['F32'].min()\n",
    "        t_final.loc[i,'miF34'] = test_df['F34'].min()\n",
    "        t_final.loc[i,'miF42'] = test_df['F42'].min()\n",
    "        t_final.loc[i,'miF43'] = test_df ['F43'].min()\n",
    "\n",
    "#         t_final.loc[i,'sFSR5'] = test_df['FSR5'].std()\n",
    "#         t_final.loc[i,'sFSR4'] = test_df['FSR4'].std()\n",
    "#         t_final.loc[i,'sF32'] = test_df['F32'].std()\n",
    "#         t_final.loc[i,'sF34'] = test_df['F34'].std()\n",
    "#         t_final.loc[i,'sF42'] = test_df['F42'].std()\n",
    "#         t_final.loc[i,'sF43'] = test_df['F43'].std()\n",
    "\n",
    "\n",
    "#         t_final.loc[i,'rFSR5'] = np.sqrt(sum(test_df['FSR5']**2)/len(test_df))\n",
    "#         t_final.loc[i,'rFSR4'] = np.sqrt(sum(test_df['FSR4']**2)/len(test_df))\n",
    "#         t_final.loc[i,'rF32'] = np.sqrt(sum(test_df['F32']**2)/len(test_df))\n",
    "#         t_final.loc[i,'rF34'] = np.sqrt(sum(test_df['F34']**2)/len(test_df))\n",
    "#         t_final.loc[i,'rF42'] = np.sqrt(sum(test_df['F42']**2)/len(test_df))\n",
    "#         t_final.loc[i,'rF43'] = np.sqrt(sum(test_df['F43']**2)/len(test_df))\n",
    "\n",
    "        t_final.loc[i,'Label'] = math.floor(int(file_split2[0])/10)\n",
    "        i+=1\n",
    "    except:\n",
    "        print(path2+file)\n",
    "i=0\n",
    "for file in os.listdir(path):\n",
    "    df = pd.DataFrame()\n",
    "    df = pd.read_csv(path+file, header=None, names=cname)\n",
    "    file_split = file.split(sep='-')\n",
    "    file_split2 = file_split[2].split(sep='.')\n",
    "     \n",
    "   \n",
    "    final.loc[i,'mFSR5'] = df['FSR5'].mean()\n",
    "    final.loc[i,'mFSR4'] = df['FSR4'].mean()\n",
    "    final.loc[i,'mF32'] = df['F32'].mean()\n",
    "    final.loc[i,'mF34'] = df['F34'].mean()\n",
    "    final.loc[i,'mF42'] = df['F42'].mean()\n",
    "    final.loc[i,'mF43'] = df['F43'].mean()\n",
    "\n",
    "#     final.loc[i,'miFSR5'] = df['FSR5'].max()\n",
    "#     final.loc[i,'miFSR4'] = df['FSR4'].max()\n",
    "    \n",
    "    \n",
    "    final.loc[i,'miF32'] = df['F32'].min()\n",
    "    final.loc[i,'miF34'] = df['F34'].min()\n",
    "    final.loc[i,'miF42'] = df['F42'].min()\n",
    "    final.loc[i,'miF43'] = df ['F43'].min()\n",
    "    \n",
    "#     final.loc[i,'sFSR5'] = df['FSR5'].std()\n",
    "#     final.loc[i,'sFSR4'] = df['FSR4'].std()\n",
    "#     final.loc[i,'sF32'] = df['F32'].std()\n",
    "#     final.loc[i,'sF34'] = df['F34'].std()\n",
    "#     final.loc[i,'sF42'] = df['F42'].std()\n",
    "#     final.loc[i,'sF43'] = df['F43'].std()\n",
    "    \n",
    "\n",
    "#     final.loc[i,'rFSR5'] = np.sqrt(sum(df['FSR5']**2)/len(df))\n",
    "#     final.loc[i,'rFSR4'] = np.sqrt(sum(df['FSR4']**2)/len(df))\n",
    "#     final.loc[i,'rF32'] = np.sqrt(sum(df['F32']**2)/len(df))\n",
    "#     final.loc[i,'rF34'] = np.sqrt(sum(df['F34']**2)/len(df))\n",
    "#     final.loc[i,'rF42'] = np.sqrt(sum(df['F42']**2)/len(df))\n",
    "#     final.loc[i,'rF43'] = np.sqrt(sum(df['F43']**2)/len(df))\n",
    "    \n",
    "    final.loc[i,'Label'] = math.floor(int(file_split2[0])/10)\n",
    "    i+=1\n",
    "    \n",
    "    \n",
    "X = final.copy()\n",
    "del X['Label']\n",
    "\n",
    "y = final['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(max_depth=3,learning_rate=0.7)\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "eval_metric = [\"merror\"]\n",
    "\n",
    "%time xgb_model.fit(X_train, y_train, eval_metric=eval_metric, eval_set=eval_set, verbose=False, early_stopping_rounds=10)\n",
    "# print('Accuracy of XGB classifier on training set: {:.2f}'\n",
    "#        .format(xgb_model.score(X_train, y_train)))\n",
    "# print('Accuracy of XGB classifier on test set: {:.2f}'\n",
    "#        .format(xgb_model.score(X_test[X_train.columns], y_test)))\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "final['p'] = xgb_model.predict(X)\n",
    "#plot_importance(xgb_model)\n",
    "#pyplot.show()\n",
    "#print(classification_report(y_test, y_pred))\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=None)\n",
    "results = cross_val_score(xgb_model, X, y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "X = final.copy()\n",
    "X = final.drop(columns=['Label','p']).copy()\n",
    "\n",
    "y = final['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "logmodel = LogisticRegression(max_iter = 200, multi_class='multinomial')\n",
    "logmodel.fit(X_train,y_train)\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#print('Accuracy of training set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "#print('Accuracy of test set: {:.2f}'.format(clf.score(X_test[X_train.columns], y_test)))\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "#print(clf.score(X_test,y_test))\n",
    "# print()\n",
    "#print(classification_report(y_test, y_pred))\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=None)\n",
    "results = cross_val_score(logmodel, X, y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "t_final[t_final.columns] = t_final[t_final.columns].apply(pd.to_numeric)\n",
    "x_pat = t_final.drop(columns=['Label'])\n",
    "t_final['lr_pred'] = clf.predict(x_pat)\n",
    "t_final['xgb_pred'] = xgb_model.predict(x_pat)\n",
    "print('patient XGB:',len(t_final[t_final['Label']==t_final['xgb_pred']])/len(t_final))\n",
    "print('patient LR:',len(t_final[t_final['Label']==t_final['lr_pred']])/len(t_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.9 ms\n",
      "Accuracy: 67.50% (23.18%)\n",
      "Accuracy: 80.00% (16.96%)\n",
      "patient XGB: 0.5\n",
      "patient LR: 0.1\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "cname = ['Ax','Ay','Az','Gx','Gy','Gz']\n",
    "final = pd.DataFrame()\n",
    "t_final = pd.DataFrame()\n",
    "path = 'C:/Users/Husse/Desktop/iGraspProject/Hardware/Samples/Wave/'\n",
    "path2 = 'C:/Users/Husse/Desktop/iGraspProject/Hardware/Patients/Wave/'\n",
    "\n",
    "for file in os.listdir(path2):\n",
    "    test_df = pd.DataFrame()\n",
    "    test_df = pd.read_csv(path2+file, header=None, names=cname)\n",
    "    file_split = file.split(sep='-')\n",
    "    file_split2 = file_split[2].split(sep='.')\n",
    "    \n",
    "    test_df['aAx'] = test_df['Ax'].abs()\n",
    "    test_df['aAy'] = test_df['Ay'].abs()\n",
    "    test_df['aAz'] = test_df['Az'].abs()\n",
    "    test_df['aGx'] = test_df['Gx'].abs()\n",
    "    test_df['aGy'] = test_df['Gy'].abs()\n",
    "    test_df['aGz'] = test_df['Gz'].abs()\n",
    "   \n",
    "    t_final.loc[i,'mAx'] = test_df['Ax'].mean()\n",
    "    t_final.loc[i,'mAy'] = test_df['Ay'].mean()\n",
    "    t_final.loc[i,'mAz'] = test_df['Az'].mean()\n",
    "    t_final.loc[i,'mGx'] = test_df['Gx'].mean()\n",
    "    t_final.loc[i,'mGy'] = test_df['Gy'].mean()\n",
    "    t_final.loc[i,'mGz'] = test_df['Gz'].mean()\n",
    "    \n",
    "#     t_final.loc[i,'sAx'] = test_df['Ax'].std()\n",
    "#     t_final.loc[i,'sAy'] = test_df['Ay'].std()\n",
    "#     t_final.loc[i,'sAz'] = test_df['Az'].std()\n",
    "#     t_final.loc[i,'sGx'] = test_df['Gx'].std()\n",
    "#     t_final.loc[i,'sGy'] = test_df['Gy'].std()\n",
    "#     t_final.loc[i,'sGz'] = test_df['Gz'].std()\n",
    "\n",
    "#     t_final.loc[i,'rAx'] = np.sqrt(sum(test_df['Ax']**2)/len(test_df))\n",
    "#     t_final.loc[i,'rAy'] = np.sqrt(sum(test_df['Ay']**2)/len(test_df))\n",
    "#     t_final.loc[i,'rAz'] = np.sqrt(sum(test_df['Az']**2)/len(test_df))\n",
    "#     t_final.loc[i,'rGx'] = np.sqrt(sum(test_df['Gx']**2)/len(test_df))\n",
    "#     t_final.loc[i,'rGy'] = np.sqrt(sum(test_df['Gy']**2)/len(test_df))\n",
    "#     t_final.loc[i,'rGz'] = np.sqrt(sum(test_df['Gz']**2)/len(test_df))\n",
    "    \n",
    "    t_final.loc[i,'SMAac'] = (test_df['Ax'].sum()+test_df['Ay'].sum()+test_df['Az'].sum())*(1/5)\n",
    "    t_final.loc[i,'SMAgy'] = (test_df['Gx'].sum()+test_df['Gy'].sum()+test_df['Gz'].sum())*(1/5)\n",
    "    \n",
    "    t_final.loc[i,'Label'] = math.floor(int(file_split2[0])/10)\n",
    "    i+=1\n",
    "\n",
    "    \n",
    "\n",
    "for file in os.listdir(path):\n",
    "    df = pd.DataFrame()\n",
    "    df = pd.read_csv(path+file, header=None, names=cname)\n",
    "    file_split = file.split(sep='-')\n",
    "    file_split2 = file_split[2].split(sep='.')\n",
    "    \n",
    "    df['aAx'] = df['Ax'].abs()\n",
    "    df['aAy'] = df['Ay'].abs()\n",
    "    df['aAz'] = df['Az'].abs()\n",
    "    df['aGx'] = df['Gx'].abs()\n",
    "    df['aGy'] = df['Gy'].abs()\n",
    "    df['aGz'] = df['Gz'].abs()\n",
    "   \n",
    "    final.loc[i,'mAx'] = df['Ax'].mean()\n",
    "    final.loc[i,'mAy'] = df['Ay'].mean()\n",
    "    final.loc[i,'mAz'] = df['Az'].mean()\n",
    "    final.loc[i,'mGx'] = df['Gx'].mean()\n",
    "    final.loc[i,'mGy'] = df['Gy'].mean()\n",
    "    final.loc[i,'mGz'] = df['Gz'].mean()\n",
    "    \n",
    "#     final.loc[i,'sAx'] = df['Ax'].std()\n",
    "#     final.loc[i,'sAy'] = df['Ay'].std()\n",
    "#     final.loc[i,'sAz'] = df['Az'].std()\n",
    "#     final.loc[i,'sGx'] = df['Gx'].std()\n",
    "#     final.loc[i,'sGy'] = df['Gy'].std()\n",
    "#     final.loc[i,'sGz'] = df['Gz'].std()\n",
    "\n",
    "#     final.loc[i,'rAx'] = np.sqrt(sum(df['Ax']**2)/len(df))\n",
    "#     final.loc[i,'rAy'] = np.sqrt(sum(df['Ay']**2)/len(df))\n",
    "#     final.loc[i,'rAz'] = np.sqrt(sum(df['Az']**2)/len(df))\n",
    "#     final.loc[i,'rGx'] = np.sqrt(sum(df['Gx']**2)/len(df))\n",
    "#     final.loc[i,'rGy'] = np.sqrt(sum(df['Gy']**2)/len(df))\n",
    "#     final.loc[i,'rGz'] = np.sqrt(sum(df['Gz']**2)/len(df))\n",
    "    \n",
    "    final.loc[i,'SMAac'] = (df['Ax'].sum()+df['Ay'].sum()+df['Az'].sum())*(1/5)\n",
    "    final.loc[i,'SMAgy'] = (df['Gx'].sum()+df['Gy'].sum()+df['Gz'].sum())*(1/5)\n",
    "    \n",
    "    final.loc[i,'Label'] = math.floor(int(file_split2[0])/10)\n",
    "    i+=1\n",
    "\n",
    "    \n",
    "X = final.copy()\n",
    "del X['Label']\n",
    "\n",
    "y = final['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(max_depth=3,learning_rate=0.7)\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "eval_metric = [\"merror\"]\n",
    "\n",
    "%time xgb_model.fit(X_train, y_train, eval_metric=eval_metric, eval_set=eval_set, verbose=False, early_stopping_rounds=10)\n",
    "# print('Accuracy of XGB classifier on training set: {:.2f}'\n",
    "#        .format(xgb_model.score(X_train, y_train)))\n",
    "# print('Accuracy of XGB classifier on test set: {:.2f}'\n",
    "#        .format(xgb_model.score(X_test[X_train.columns], y_test)))\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "final['p'] = xgb_model.predict(X)\n",
    "# plot_importance(xgb_model)\n",
    "# pyplot.show()\n",
    "# print(classification_report(y_test, y_pred))\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=None)\n",
    "results = cross_val_score(xgb_model, X, y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "X = final.drop(columns=['Label','p']).copy()\n",
    "\n",
    "\n",
    "y = final['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "logmodel = LogisticRegression(max_iter = 200, multi_class='multinomial')\n",
    "logmodel.fit(X_train,y_train)\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# print('Accuracy of training set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "# print('Accuracy of test set: {:.2f}'.format(clf.score(X_test[X_train.columns], y_test)))\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "#print(clf.score(X_test,y_test))\n",
    "#print(classification_report(y_test, y_pred))\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=None)\n",
    "results = cross_val_score(logmodel, X, y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "t_final[t_final.columns] = t_final[t_final.columns].apply(pd.to_numeric)\n",
    "x_pat = t_final.drop(columns=['Label'])\n",
    "t_final['lr_pred'] = clf.predict(x_pat)\n",
    "t_final['xgb_pred'] = xgb_model.predict(x_pat)\n",
    "print('patient XGB:',len(t_final[t_final['Label']==t_final['xgb_pred']])/len(t_final))\n",
    "print('patient LR:',len(t_final[t_final['Label']==t_final['lr_pred']])/len(t_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 58.9 ms\n",
      "Accuracy of XGB classifier on training set: 0.96\n",
      "Accuracy of XGB classifier on test set: 1.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         2\n",
      "         1.0       1.00      1.00      1.00         4\n",
      "         2.0       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "Accuracy: 85.71% (9.04%)\n"
     ]
    }
   ],
   "source": [
    "X = final.copy()\n",
    "del X['Label']\n",
    "\n",
    "y = final['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(max_depth=3,learning_rate=0.7)\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "eval_metric = [\"merror\"]\n",
    "\n",
    "%time xgb_model.fit(X_train, y_train, eval_metric=eval_metric, eval_set=eval_set, verbose=False, early_stopping_rounds=10)\n",
    "print('Accuracy of XGB classifier on training set: {:.2f}'\n",
    "       .format(xgb_model.score(X_train, y_train)))\n",
    "print('Accuracy of XGB classifier on test set: {:.2f}'\n",
    "       .format(xgb_model.score(X_test[X_train.columns], y_test)))\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "final['p'] = xgb_model.predict(X)\n",
    "plot_importance(xgb_model)\n",
    "pyplot.show()\n",
    "print(classification_report(y_test, y_pred))\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=None)\n",
    "results = cross_val_score(xgb_model, X, y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\husse\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\husse\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\husse\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\husse\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\husse\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\husse\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of training set: 1.00\n",
      "Accuracy of test set: 0.73\n",
      "0.7272727272727273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      1.00      0.80         2\n",
      "         1.0       0.67      0.50      0.57         4\n",
      "         2.0       0.80      0.80      0.80         5\n",
      "\n",
      "    accuracy                           0.73        11\n",
      "   macro avg       0.71      0.77      0.72        11\n",
      "weighted avg       0.73      0.73      0.72        11\n",
      "\n",
      "Accuracy: 91.43% (11.43%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\husse\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "X = final.copy()\n",
    "del X['Label']\n",
    "\n",
    "y = final['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "logmodel = LogisticRegression(max_iter = 100, multi_class='multinomial')\n",
    "logmodel.fit(X_train,y_train)\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy of training set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of test set: {:.2f}'.format(clf.score(X_test[X_train.columns], y_test)))\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(clf.score(X_test,y_test))\n",
    "# print()\n",
    "print(classification_report(y_test, y_pred))\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=None)\n",
    "results = cross_val_score(logmodel, X, y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "\n",
    "# cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "# class_names=[0,1,2] # name  of classes\n",
    "# fig, ax = plt.subplots()\n",
    "# tick_marks = np.arange(len(class_names))\n",
    "# plt.xticks(tick_marks, class_names)\n",
    "# plt.yticks(tick_marks, class_names)\n",
    "# # create heatmap\n",
    "# sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "# ax.xaxis.set_label_position(\"top\")\n",
    "# plt.tight_layout()\n",
    "# plt.title('Confusion matrix', y=1.1)\n",
    "# plt.ylabel('Actual label')\n",
    "# plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-164fbf2c7c9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\husse\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    146\u001b[0m         X, y = check_X_y(X, y, dtype=np.float64,\n\u001b[0;32m    147\u001b[0m                          \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m                          accept_large_sparse=False)\n\u001b[0m\u001b[0;32m    149\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\husse\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    756\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mc:\\users\\husse\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 578\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\husse\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     (type_err,\n\u001b[1;32m---> 60\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m     61\u001b[0m             )\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "X = final.copy()\n",
    "del X['Label']\n",
    "\n",
    "y = final['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred, average='macro'))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mFSR5</th>\n",
       "      <th>mFSR4</th>\n",
       "      <th>mF32</th>\n",
       "      <th>mF34</th>\n",
       "      <th>mF42</th>\n",
       "      <th>mF43</th>\n",
       "      <th>miFSR5</th>\n",
       "      <th>miFSR4</th>\n",
       "      <th>miF32</th>\n",
       "      <th>miF34</th>\n",
       "      <th>...</th>\n",
       "      <th>sF34</th>\n",
       "      <th>sF42</th>\n",
       "      <th>sF43</th>\n",
       "      <th>rFSR5</th>\n",
       "      <th>rFSR4</th>\n",
       "      <th>rF32</th>\n",
       "      <th>rF34</th>\n",
       "      <th>rF42</th>\n",
       "      <th>rF43</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.901408</td>\n",
       "      <td>6.957746</td>\n",
       "      <td>-9.464789</td>\n",
       "      <td>7901.070423</td>\n",
       "      <td>13888.619718</td>\n",
       "      <td>-1858.704225</td>\n",
       "      <td>197.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>-308.0</td>\n",
       "      <td>7616.0</td>\n",
       "      <td>...</td>\n",
       "      <td>109.846558</td>\n",
       "      <td>78.440945</td>\n",
       "      <td>85.925615</td>\n",
       "      <td>54.007563</td>\n",
       "      <td>172.046423</td>\n",
       "      <td>126.269888</td>\n",
       "      <td>7901.823216</td>\n",
       "      <td>13888.838108</td>\n",
       "      <td>1860.661339</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114.361111</td>\n",
       "      <td>8.458333</td>\n",
       "      <td>49.708333</td>\n",
       "      <td>7880.166667</td>\n",
       "      <td>13843.722222</td>\n",
       "      <td>-2097.111111</td>\n",
       "      <td>4490.0</td>\n",
       "      <td>1081.0</td>\n",
       "      <td>-92.0</td>\n",
       "      <td>7716.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.802837</td>\n",
       "      <td>61.318201</td>\n",
       "      <td>55.022545</td>\n",
       "      <td>714.302554</td>\n",
       "      <td>134.678063</td>\n",
       "      <td>385.059898</td>\n",
       "      <td>7880.595649</td>\n",
       "      <td>13843.856134</td>\n",
       "      <td>2097.822787</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>215.632353</td>\n",
       "      <td>-295.750000</td>\n",
       "      <td>233.573529</td>\n",
       "      <td>6582.058824</td>\n",
       "      <td>14532.411765</td>\n",
       "      <td>-1538.941176</td>\n",
       "      <td>3371.0</td>\n",
       "      <td>3176.0</td>\n",
       "      <td>-8953.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1764.960918</td>\n",
       "      <td>989.922750</td>\n",
       "      <td>890.138776</td>\n",
       "      <td>1254.215756</td>\n",
       "      <td>2778.555425</td>\n",
       "      <td>2101.039081</td>\n",
       "      <td>6811.224214</td>\n",
       "      <td>14565.593972</td>\n",
       "      <td>1774.552006</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124.750000</td>\n",
       "      <td>22.416667</td>\n",
       "      <td>41.777778</td>\n",
       "      <td>8384.555556</td>\n",
       "      <td>13088.555556</td>\n",
       "      <td>-3305.444444</td>\n",
       "      <td>4496.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>-408.0</td>\n",
       "      <td>8088.0</td>\n",
       "      <td>...</td>\n",
       "      <td>86.747308</td>\n",
       "      <td>71.074824</td>\n",
       "      <td>59.784799</td>\n",
       "      <td>738.065377</td>\n",
       "      <td>177.023382</td>\n",
       "      <td>419.590707</td>\n",
       "      <td>8384.998059</td>\n",
       "      <td>13088.745853</td>\n",
       "      <td>3305.977549</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118.369863</td>\n",
       "      <td>13.931507</td>\n",
       "      <td>52.876712</td>\n",
       "      <td>8470.684932</td>\n",
       "      <td>12995.506849</td>\n",
       "      <td>-3418.575342</td>\n",
       "      <td>4496.0</td>\n",
       "      <td>1183.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>8316.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.837825</td>\n",
       "      <td>60.889500</td>\n",
       "      <td>64.568206</td>\n",
       "      <td>727.668890</td>\n",
       "      <td>144.278602</td>\n",
       "      <td>399.129189</td>\n",
       "      <td>8471.002334</td>\n",
       "      <td>12995.647541</td>\n",
       "      <td>3419.176701</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mFSR5       mFSR4        mF32         mF34          mF42         mF43  \\\n",
       "0    0.901408    6.957746   -9.464789  7901.070423  13888.619718 -1858.704225   \n",
       "1  114.361111    8.458333   49.708333  7880.166667  13843.722222 -2097.111111   \n",
       "2  215.632353 -295.750000  233.573529  6582.058824  14532.411765 -1538.941176   \n",
       "3  124.750000   22.416667   41.777778  8384.555556  13088.555556 -3305.444444   \n",
       "4  118.369863   13.931507   52.876712  8470.684932  12995.506849 -3418.575342   \n",
       "\n",
       "   miFSR5  miFSR4   miF32   miF34  ...         sF34        sF42        sF43  \\\n",
       "0   197.0   550.0  -308.0  7616.0  ...   109.846558   78.440945   85.925615   \n",
       "1  4490.0  1081.0   -92.0  7716.0  ...    82.802837   61.318201   55.022545   \n",
       "2  3371.0  3176.0 -8953.0   576.0  ...  1764.960918  989.922750  890.138776   \n",
       "3  4496.0  1260.0  -408.0  8088.0  ...    86.747308   71.074824   59.784799   \n",
       "4  4496.0  1183.0  -130.0  8316.0  ...    73.837825   60.889500   64.568206   \n",
       "\n",
       "         rFSR5        rFSR4         rF32         rF34          rF42  \\\n",
       "0    54.007563   172.046423   126.269888  7901.823216  13888.838108   \n",
       "1   714.302554   134.678063   385.059898  7880.595649  13843.856134   \n",
       "2  1254.215756  2778.555425  2101.039081  6811.224214  14565.593972   \n",
       "3   738.065377   177.023382   419.590707  8384.998059  13088.745853   \n",
       "4   727.668890   144.278602   399.129189  8471.002334  12995.647541   \n",
       "\n",
       "          rF43    p  \n",
       "0  1860.661339  0.0  \n",
       "1  2097.822787  0.0  \n",
       "2  1774.552006  0.0  \n",
       "3  3305.977549  0.0  \n",
       "4  3419.176701  0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster  Label\n",
       "0        1.0       6\n",
       "         2.0      12\n",
       "1        0.0      10\n",
       "         1.0       1\n",
       "2        2.0       2\n",
       "3        1.0       2\n",
       "4        2.0       1\n",
       "5        1.0       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "X = final.copy()\n",
    "del X['Label']\n",
    "\n",
    "y = final['Label'].copy().to_frame()\n",
    "\n",
    "y_pred = MeanShift().fit_predict(X)\n",
    "y['cluster'] = list(y_pred)\n",
    "y['count']=1\n",
    "y.groupby(['cluster','Label'])['count'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster  Label\n",
       "0        0.0      10\n",
       "         1.0       1\n",
       "1        1.0       7\n",
       "         2.0      13\n",
       "2        1.0       2\n",
       "         2.0       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = final.copy()\n",
    "del X['Label']\n",
    "\n",
    "y = final['Label'].copy().to_frame()\n",
    "\n",
    "y_pred = KMeans(n_clusters=3).fit_predict(X)\n",
    "y['cluster'] = list(y_pred)\n",
    "y['count']=1\n",
    "y.groupby(['cluster','Label'])['count'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
